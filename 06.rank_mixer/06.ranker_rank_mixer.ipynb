{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3479793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/site-packages/aliyunsdkcore/auth/algorithm/sha_hmac256.py:20: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.\n",
      "  from cryptography.hazmat.backends import default_backend\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771329a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "675e89fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training RANKMIXER Model ===\n",
      "Epoch 1/20, Avg Loss: 0.6156, Test AUC: 0.8407\n",
      "Epoch 2/20, Avg Loss: 0.4348, Test AUC: 0.8939\n",
      "Epoch 3/20, Avg Loss: 0.3836, Test AUC: 0.9109\n",
      "Epoch 4/20, Avg Loss: 0.3614, Test AUC: 0.9178\n",
      "Epoch 5/20, Avg Loss: 0.3499, Test AUC: 0.9205\n",
      "Epoch 6/20, Avg Loss: 0.3403, Test AUC: 0.9240\n",
      "Epoch 7/20, Avg Loss: 0.3325, Test AUC: 0.9281\n",
      "Epoch 8/20, Avg Loss: 0.3302, Test AUC: 0.9268\n",
      "Epoch 9/20, Avg Loss: 0.3214, Test AUC: 0.9315\n",
      "Epoch 10/20, Avg Loss: 0.3168, Test AUC: 0.9326\n",
      "Epoch 11/20, Avg Loss: 0.3110, Test AUC: 0.9340\n",
      "Epoch 12/20, Avg Loss: 0.3088, Test AUC: 0.9324\n",
      "Epoch 13/20, Avg Loss: 0.3038, Test AUC: 0.9353\n",
      "Epoch 14/20, Avg Loss: 0.3009, Test AUC: 0.9371\n",
      "Epoch 15/20, Avg Loss: 0.2951, Test AUC: 0.9365\n",
      "Epoch 16/20, Avg Loss: 0.2950, Test AUC: 0.9405\n",
      "Epoch 17/20, Avg Loss: 0.2900, Test AUC: 0.9382\n",
      "Epoch 18/20, Avg Loss: 0.2855, Test AUC: 0.9405\n",
      "Epoch 19/20, Avg Loss: 0.2857, Test AUC: 0.9399\n",
      "Epoch 20/20, Avg Loss: 0.2827, Test AUC: 0.9430\n",
      "=== Training MHA Model ===\n",
      "Epoch 1/20, Avg Loss: 0.6056, Test AUC: 0.8306\n",
      "Epoch 2/20, Avg Loss: 0.4594, Test AUC: 0.8785\n",
      "Epoch 3/20, Avg Loss: 0.4115, Test AUC: 0.8886\n",
      "Epoch 4/20, Avg Loss: 0.3889, Test AUC: 0.8998\n",
      "Epoch 5/20, Avg Loss: 0.3736, Test AUC: 0.9078\n",
      "Epoch 6/20, Avg Loss: 0.3626, Test AUC: 0.9112\n",
      "Epoch 7/20, Avg Loss: 0.3515, Test AUC: 0.9182\n",
      "Epoch 8/20, Avg Loss: 0.3409, Test AUC: 0.9172\n",
      "Epoch 9/20, Avg Loss: 0.3372, Test AUC: 0.9229\n",
      "Epoch 10/20, Avg Loss: 0.3299, Test AUC: 0.9234\n",
      "Epoch 11/20, Avg Loss: 0.3233, Test AUC: 0.9241\n",
      "Epoch 12/20, Avg Loss: 0.3197, Test AUC: 0.9260\n",
      "Epoch 13/20, Avg Loss: 0.3100, Test AUC: 0.9282\n",
      "Epoch 14/20, Avg Loss: 0.3060, Test AUC: 0.9319\n",
      "Epoch 15/20, Avg Loss: 0.3036, Test AUC: 0.9307\n",
      "Epoch 16/20, Avg Loss: 0.2987, Test AUC: 0.9342\n",
      "Epoch 17/20, Avg Loss: 0.2931, Test AUC: 0.9346\n",
      "Epoch 18/20, Avg Loss: 0.2890, Test AUC: 0.9364\n",
      "Epoch 19/20, Avg Loss: 0.2885, Test AUC: 0.9349\n",
      "Epoch 20/20, Avg Loss: 0.2847, Test AUC: 0.9368\n",
      "\n",
      "=== Final AUC Comparison ===\n",
      "RankMixer AUC: 0.9430\n",
      "MHA AUC: 0.9368\n",
      "AUC Difference (RankMixer - MHA): 0.0062\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 判断是否使用TF2.x，如果是则切换到兼容模式\n",
    "if tf.__version__.startswith('2'):\n",
    "    import tensorflow.compat.v1 as tf\n",
    "    tf.disable_v2_behavior()\n",
    "\n",
    "# 固定随机种子\n",
    "np.random.seed(2024)\n",
    "tf.set_random_seed(2024)\n",
    "\n",
    "# ===================== 1. 生成电商样例数据 =====================\n",
    "def generate_ecommerce_data():\n",
    "    # 数据参数\n",
    "    user_num = 10000\n",
    "    item_num = 5000\n",
    "    sample_num = 100000\n",
    "    user_feat_dim = 16  # 用户特征：年龄、性别、购买力等\n",
    "    item_feat_dim = 16  # 商品特征：品类、价格、评分等\n",
    "    behavior_feat_dim = 8  # 行为特征：点击频次、浏览时长等\n",
    "\n",
    "    # 生成连续特征\n",
    "    user_feats = np.random.normal(0, 1, (sample_num, user_feat_dim))\n",
    "    item_feats = np.random.normal(0, 1, (sample_num, item_feat_dim))\n",
    "    behavior_feats = np.random.normal(0, 1, (sample_num, behavior_feat_dim))\n",
    "\n",
    "    # 生成点击标签（基于用户-商品特征内积 + 噪声）\n",
    "    logits = np.sum(user_feats * item_feats, axis=1) + np.random.normal(0, 0.5, sample_num)\n",
    "    labels = (logits > 0).astype(np.float32)\n",
    "\n",
    "    # 合并特征并划分训练/测试集\n",
    "    all_feats = np.concatenate([user_feats, item_feats, behavior_feats], axis=1)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        all_feats, labels, test_size=0.2, random_state=2024\n",
    "    )\n",
    "    return x_train, x_test, y_train, y_test, all_feats.shape[1]\n",
    "\n",
    "# ===================== 2. 定义 RankMixer 核心层 =====================\n",
    "def rank_mixer_layer(inputs, token_num=4, head_num=2, hidden_dim=64):\n",
    "    batch_size = tf.shape(inputs)[0]\n",
    "    input_dim = inputs.get_shape().as_list()[-1]\n",
    "\n",
    "    # Step1: 特征 Token 化（均匀划分）\n",
    "    token_dim = input_dim // token_num\n",
    "    tokens = tf.reshape(inputs, [batch_size, token_num, token_dim])  # [B, T, D_t]\n",
    "\n",
    "    # Step2: 多头 Token 混合（无参跨 Token 交互）\n",
    "    head_dim = token_dim // head_num\n",
    "    tokens_split = tf.reshape(tokens, [batch_size, token_num, head_num, head_dim])\n",
    "    tokens_split = tf.transpose(tokens_split, [0, 2, 1, 3])  # [B, H, T, D_h]\n",
    "\n",
    "    mixed_tokens = []\n",
    "    for h in range(head_num):\n",
    "        head_token = tokens_split[:, h, :, :]\n",
    "        # 相邻 Token 拼接实现混合\n",
    "#         head_mixed = tf.concat([head_token[:, 1:, :], head_token[:, :-1, :]], axis=-1)\n",
    "        head_mixed = head_token\n",
    "        \n",
    "        mixed_tokens.append(head_mixed)\n",
    "    mixed_tokens = tf.concat(mixed_tokens, axis=-1)  # [B, T-1, H*2*D_h]\n",
    "\n",
    "    # Step3: 逐 Token 前馈网络\n",
    "    ff_out = tf.layers.dense(mixed_tokens, hidden_dim, activation=tf.nn.relu)\n",
    "    ff_out = tf.layers.dense(ff_out, token_dim)\n",
    "    return tf.reduce_mean(ff_out, axis=1)  # Token 维度聚合 [B, D_t]\n",
    "\n",
    "# ===================== 3. 定义 MHA 核心层 =====================\n",
    "def mha_layer(inputs, head_num=4, hidden_dim=64):\n",
    "    batch_size = tf.shape(inputs)[0]\n",
    "    input_dim = inputs.get_shape().as_list()[-1]\n",
    "\n",
    "    # 构造 Q/K/V 向量\n",
    "    q = tf.layers.dense(inputs, hidden_dim, activation=tf.nn.relu)\n",
    "    k = tf.layers.dense(inputs, hidden_dim, activation=tf.nn.relu)\n",
    "    v = tf.layers.dense(inputs, hidden_dim, activation=tf.nn.relu)\n",
    "\n",
    "    # 适配 MHA 3D 输入格式 [B, T, D]，构造 T=1 的序列\n",
    "    q = tf.expand_dims(q, axis=1)\n",
    "    k = tf.expand_dims(k, axis=1)\n",
    "    v = tf.expand_dims(v, axis=1)\n",
    "\n",
    "    # 自定义多头注意力计算\n",
    "    def scaled_dot_product_attention(q, k, v):\n",
    "        matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "        dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "        scaled_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "        attention_weights = tf.nn.softmax(scaled_logits, axis=-1)\n",
    "        output = tf.matmul(attention_weights, v)\n",
    "        return output\n",
    "\n",
    "    # 分头计算\n",
    "    q_split = tf.split(q, head_num, axis=-1)\n",
    "    k_split = tf.split(k, head_num, axis=-1)\n",
    "    v_split = tf.split(v, head_num, axis=-1)\n",
    "\n",
    "    outputs = []\n",
    "    for q_h, k_h, v_h in zip(q_split, k_split, v_split):\n",
    "        outputs.append(scaled_dot_product_attention(q_h, k_h, v_h))\n",
    "    concat_output = tf.concat(outputs, axis=-1)\n",
    "    \n",
    "    # 全连接层整合\n",
    "    output = tf.layers.dense(concat_output, hidden_dim)\n",
    "    return tf.squeeze(output, axis=1)\n",
    "\n",
    "# ===================== 4. 构建完整模型 =====================\n",
    "def build_model(inputs, labels, model_type=\"rankmixer\"):\n",
    "    input_layer = tf.reshape(inputs, [-1, inputs.get_shape().as_list()[-1]])\n",
    "    # 共享底层特征映射\n",
    "    hidden = tf.layers.dense(input_layer, 128, activation=tf.nn.relu)\n",
    "    hidden = tf.layers.dropout(hidden, rate=0.2, training=True)\n",
    "\n",
    "    # 核心层选择\n",
    "    if model_type == \"rankmixer\":\n",
    "        core_out = rank_mixer_layer(hidden)\n",
    "    elif model_type == \"mha\":\n",
    "        core_out = mha_layer(hidden)\n",
    "    else:\n",
    "        raise ValueError(\"model_type must be 'rankmixer' or 'mha'\")\n",
    "\n",
    "    # 输出层（二分类）\n",
    "    logits = tf.layers.dense(core_out, 1)\n",
    "    preds = tf.nn.sigmoid(logits)\n",
    "\n",
    "    # 损失函数与优化器\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits=logits, labels=tf.reshape(labels, [-1, 1])\n",
    "        )\n",
    "    )\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "    return preds, loss, optimizer\n",
    "\n",
    "# ===================== 5. 模型训练与评估 =====================\n",
    "def train_and_evaluate(model_type, x_train, x_test, y_train, y_test, feat_dim):\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        # 定义占位符\n",
    "        x_ph = tf.placeholder(tf.float32, [None, feat_dim])\n",
    "        y_ph = tf.placeholder(tf.float32, [None])\n",
    "        preds, loss, optimizer = build_model(x_ph, y_ph, model_type)\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        # 训练参数\n",
    "        epochs = 20\n",
    "        batch_size = 256\n",
    "        train_steps = len(x_train) // batch_size\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "            print(\"=== Training {} Model ===\".format(model_type.upper()))\n",
    "            for epoch in range(epochs):\n",
    "                epoch_loss = 0.0\n",
    "                # 批次训练\n",
    "                for step in range(train_steps):\n",
    "                    start_idx = step * batch_size\n",
    "                    end_idx = start_idx + batch_size\n",
    "                    batch_x = x_train[start_idx:end_idx]\n",
    "                    batch_y = y_train[start_idx:end_idx]\n",
    "                    _, batch_loss_val = sess.run(\n",
    "                        [optimizer, loss],\n",
    "                        feed_dict={x_ph: batch_x, y_ph: batch_y}\n",
    "                    )\n",
    "                    epoch_loss += batch_loss_val\n",
    "                # 计算测试集 AUC\n",
    "                y_pred_val = sess.run(preds, feed_dict={x_ph: x_test, y_ph: y_test})\n",
    "                auc_val = roc_auc_score(y_test, y_pred_val)\n",
    "                print(\"Epoch {}/{}, Avg Loss: {:.4f}, Test AUC: {:.4f}\".format(\n",
    "                    epoch+1, epochs, epoch_loss/train_steps, auc_val\n",
    "                ))\n",
    "        return auc_val\n",
    "\n",
    "# ===================== 6. 主函数执行 =====================\n",
    "if __name__ == \"__main__\":\n",
    "    # 生成数据\n",
    "    x_train, x_test, y_train, y_test, feat_dim = generate_ecommerce_data()\n",
    "\n",
    "    # 训练并评估两个模型\n",
    "    auc_rankmixer = train_and_evaluate(\"rankmixer\", x_train, x_test, y_train, y_test, feat_dim)\n",
    "    auc_mha = train_and_evaluate(\"mha\", x_train, x_test, y_train, y_test, feat_dim)\n",
    "\n",
    "    # 结果对比\n",
    "    print(\"\\n=== Final AUC Comparison ===\")\n",
    "    print(\"RankMixer AUC: {:.4f}\".format(auc_rankmixer))\n",
    "    print(\"MHA AUC: {:.4f}\".format(auc_mha))\n",
    "    print(\"AUC Difference (RankMixer - MHA): {:.4f}\".format(auc_rankmixer - auc_mha))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3409ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90152e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1279d861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "270cdac3",
   "metadata": {},
   "source": [
    "### 1.0 简单的token混合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "335889d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('[rank_mixer_layer] inputs static shape:', [None, 128])\n",
      "('[rank_mixer_layer] batch_size (dynamic):', <tf.Tensor 'strided_slice:0' shape=() dtype=int32>)\n",
      "('[rank_mixer_layer] input_dim:', 128)\n",
      "('[rank_mixer_layer] token_dim:', 32)\n",
      "('[rank_mixer_layer] tokens static shape:', [None, 4, 32])\n",
      "('[rank_mixer_layer] head_dim:', 16)\n",
      "('[rank_mixer_layer] tokens_split static shape:', [None, 4, 2, 16])\n",
      "('[rank_mixer_layer] tokens_split static shape after transpose:', [None, 2, 4, 16])\n",
      "('[rank_mixer_layer] head_token[0] static shape:', [None, 4, 16])\n",
      "('[rank_mixer_layer] head_mixed[0] static shape:', [None, 4, 16])\n",
      "('[rank_mixer_layer] head_token[1] static shape:', [None, 4, 16])\n",
      "('[rank_mixer_layer] head_mixed[1] static shape:', [None, 4, 16])\n",
      "('[rank_mixer_layer] mixed_tokens static shape:', [None, 4, 32])\n",
      "('[rank_mixer_layer] ff_out static shape after first dense:', [None, 4, 64])\n",
      "('[rank_mixer_layer] ff_out static shape after second dense:', [None, 4, 32])\n",
      "('[rank_mixer_layer] output static shape:', [None, 32])\n",
      "=== Training RANKMIXER Model ===\n",
      "Epoch 1/20, Avg Loss: 0.6125, Test AUC: 0.8442\n",
      "Epoch 2/20, Avg Loss: 0.4296, Test AUC: 0.8990\n",
      "Epoch 3/20, Avg Loss: 0.3803, Test AUC: 0.9123\n",
      "Epoch 4/20, Avg Loss: 0.3569, Test AUC: 0.9206\n",
      "Epoch 5/20, Avg Loss: 0.3472, Test AUC: 0.9234\n",
      "Epoch 6/20, Avg Loss: 0.3332, Test AUC: 0.9262\n",
      "Epoch 7/20, Avg Loss: 0.3260, Test AUC: 0.9276\n",
      "Epoch 8/20, Avg Loss: 0.3192, Test AUC: 0.9328\n",
      "Epoch 9/20, Avg Loss: 0.3171, Test AUC: 0.9345\n",
      "Epoch 10/20, Avg Loss: 0.3090, Test AUC: 0.9357\n",
      "Epoch 11/20, Avg Loss: 0.3033, Test AUC: 0.9368\n",
      "Epoch 12/20, Avg Loss: 0.3000, Test AUC: 0.9371\n",
      "Epoch 13/20, Avg Loss: 0.2946, Test AUC: 0.9374\n",
      "Epoch 14/20, Avg Loss: 0.2907, Test AUC: 0.9414\n",
      "Epoch 15/20, Avg Loss: 0.2884, Test AUC: 0.9398\n",
      "Epoch 16/20, Avg Loss: 0.2859, Test AUC: 0.9404\n",
      "Epoch 17/20, Avg Loss: 0.2825, Test AUC: 0.9405\n",
      "Epoch 18/20, Avg Loss: 0.2788, Test AUC: 0.9448\n",
      "Epoch 19/20, Avg Loss: 0.2757, Test AUC: 0.9445\n",
      "Epoch 20/20, Avg Loss: 0.2728, Test AUC: 0.9440\n",
      "=== Training MHA Model ===\n",
      "Epoch 1/20, Avg Loss: 0.6096, Test AUC: 0.8222\n",
      "Epoch 2/20, Avg Loss: 0.4678, Test AUC: 0.8757\n",
      "Epoch 3/20, Avg Loss: 0.4173, Test AUC: 0.8957\n",
      "Epoch 4/20, Avg Loss: 0.3863, Test AUC: 0.9019\n",
      "Epoch 5/20, Avg Loss: 0.3737, Test AUC: 0.9088\n",
      "Epoch 6/20, Avg Loss: 0.3595, Test AUC: 0.9108\n",
      "Epoch 7/20, Avg Loss: 0.3508, Test AUC: 0.9183\n",
      "Epoch 8/20, Avg Loss: 0.3414, Test AUC: 0.9150\n",
      "Epoch 9/20, Avg Loss: 0.3334, Test AUC: 0.9227\n",
      "Epoch 10/20, Avg Loss: 0.3286, Test AUC: 0.9250\n",
      "Epoch 11/20, Avg Loss: 0.3225, Test AUC: 0.9263\n",
      "Epoch 12/20, Avg Loss: 0.3132, Test AUC: 0.9250\n",
      "Epoch 13/20, Avg Loss: 0.3098, Test AUC: 0.9291\n",
      "Epoch 14/20, Avg Loss: 0.3037, Test AUC: 0.9310\n",
      "Epoch 15/20, Avg Loss: 0.2985, Test AUC: 0.9320\n",
      "Epoch 16/20, Avg Loss: 0.2939, Test AUC: 0.9346\n",
      "Epoch 17/20, Avg Loss: 0.2908, Test AUC: 0.9349\n",
      "Epoch 18/20, Avg Loss: 0.2906, Test AUC: 0.9381\n",
      "Epoch 19/20, Avg Loss: 0.2833, Test AUC: 0.9406\n",
      "Epoch 20/20, Avg Loss: 0.2797, Test AUC: 0.9382\n",
      "\n",
      "=== Final AUC Comparison ===\n",
      "RankMixer AUC: 0.9440\n",
      "MHA AUC: 0.9382\n",
      "AUC Difference (RankMixer - MHA): 0.0059\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 判断是否使用TF2.x，如果是则切换到兼容模式\n",
    "if tf.__version__.startswith('2'):\n",
    "    import tensorflow.compat.v1 as tf\n",
    "    tf.disable_v2_behavior()\n",
    "\n",
    "# 固定随机种子\n",
    "np.random.seed(2024)\n",
    "tf.set_random_seed(2024)\n",
    "\n",
    "# ===================== 1. 生成电商样例数据 =====================\n",
    "def generate_ecommerce_data():\n",
    "    # 数据参数\n",
    "    user_num = 10000\n",
    "    item_num = 5000\n",
    "    sample_num = 100000\n",
    "    user_feat_dim = 16  # 用户特征：年龄、性别、购买力等\n",
    "    item_feat_dim = 16  # 商品特征：品类、价格、评分等\n",
    "    behavior_feat_dim = 8  # 行为特征：点击频次、浏览时长等\n",
    "\n",
    "    # 生成连续特征\n",
    "    user_feats = np.random.normal(0, 1, (sample_num, user_feat_dim))\n",
    "    item_feats = np.random.normal(0, 1, (sample_num, item_feat_dim))\n",
    "    behavior_feats = np.random.normal(0, 1, (sample_num, behavior_feat_dim))\n",
    "\n",
    "    # 生成点击标签（基于用户-商品特征内积 + 噪声）\n",
    "    logits = np.sum(user_feats * item_feats, axis=1) + np.random.normal(0, 0.5, sample_num)\n",
    "    labels = (logits > 0).astype(np.float32)\n",
    "\n",
    "    # 合并特征并划分训练/测试集\n",
    "    all_feats = np.concatenate([user_feats, item_feats, behavior_feats], axis=1)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        all_feats, labels, test_size=0.2, random_state=2024\n",
    "    )\n",
    "    return x_train, x_test, y_train, y_test, all_feats.shape[1]\n",
    "\n",
    "# ===================== 2. 定义 RankMixer 核心层 =====================\n",
    "def rank_mixer_layer(inputs, token_num=4, head_num=2, hidden_dim=64):\n",
    "    # 打印输入 shape\n",
    "    inputs_shape = inputs.get_shape().as_list()\n",
    "    inputs = tf.Print(inputs, [tf.shape(inputs)], message=\"[rank_mixer_layer] inputs shape: \", summarize=10)\n",
    "    print(\"[rank_mixer_layer] inputs static shape:\", inputs_shape)\n",
    "    \n",
    "    batch_size = tf.shape(inputs)[0]\n",
    "    input_dim = inputs.get_shape().as_list()[-1]\n",
    "    print(\"[rank_mixer_layer] batch_size (dynamic):\", batch_size)\n",
    "    print(\"[rank_mixer_layer] input_dim:\", input_dim)\n",
    "\n",
    "    # Step1: 特征 Token 化（均匀划分）\n",
    "    token_dim = input_dim // token_num\n",
    "    print(\"[rank_mixer_layer] token_dim:\", token_dim)\n",
    "    tokens = tf.reshape(inputs, [batch_size, token_num, token_dim])  # [B, T, D_t]\n",
    "    tokens_shape = tokens.get_shape().as_list()\n",
    "    tokens = tf.Print(tokens, [tf.shape(tokens)], message=\"[rank_mixer_layer] tokens shape after reshape: \", summarize=10)\n",
    "    print(\"[rank_mixer_layer] tokens static shape:\", tokens_shape)\n",
    "\n",
    "    # Step2: 多头 Token 混合（无参跨 Token 交互）\n",
    "    head_dim = token_dim // head_num\n",
    "    print(\"[rank_mixer_layer] head_dim:\", head_dim)\n",
    "    tokens_split = tf.reshape(tokens, [batch_size, token_num, head_num, head_dim])\n",
    "    tokens_split_shape = tokens_split.get_shape().as_list()\n",
    "    tokens_split = tf.Print(tokens_split, [tf.shape(tokens_split)], message=\"[rank_mixer_layer] tokens_split shape after reshape: \", summarize=10)\n",
    "    print(\"[rank_mixer_layer] tokens_split static shape:\", tokens_split_shape)\n",
    "    \n",
    "    tokens_split = tf.transpose(tokens_split, [0, 2, 1, 3])  # [B, H, T, D_h]\n",
    "    tokens_split_shape_transposed = tokens_split.get_shape().as_list()\n",
    "    tokens_split = tf.Print(tokens_split, [tf.shape(tokens_split)], message=\"[rank_mixer_layer] tokens_split shape after transpose: \", summarize=10)\n",
    "    print(\"[rank_mixer_layer] tokens_split static shape after transpose:\", tokens_split_shape_transposed)\n",
    "\n",
    "    mixed_tokens = []\n",
    "    for h in range(head_num):\n",
    "        head_token = tokens_split[:, h, :, :]\n",
    "        head_token_shape = head_token.get_shape().as_list()\n",
    "        head_token = tf.Print(head_token, [tf.shape(head_token)], message=\"[rank_mixer_layer] head_token[{}] shape: \".format(h), summarize=10)\n",
    "        print(\"[rank_mixer_layer] head_token[{}] static shape:\".format(h), head_token_shape)\n",
    "        \n",
    "#         # 相邻 Token 拼接实现混合\n",
    "#         head_token_shift1 = head_token[:, 1:, :]\n",
    "#         head_token_shift2 = head_token[:, :-1, :]\n",
    "#         head_token_shift1_shape = head_token_shift1.get_shape().as_list()\n",
    "#         head_token_shift2_shape = head_token_shift2.get_shape().as_list()\n",
    "#         head_token_shift1 = tf.Print(head_token_shift1, [tf.shape(head_token_shift1)], message=\"[rank_mixer_layer] head_token[{}] shift1 ([:, 1:, :]) shape: \".format(h), summarize=10)\n",
    "#         head_token_shift2 = tf.Print(head_token_shift2, [tf.shape(head_token_shift2)], message=\"[rank_mixer_layer] head_token[{}] shift2 ([:, :-1, :]) shape: \".format(h), summarize=10)\n",
    "#         print(\"[rank_mixer_layer] head_token[{}] shift1 static shape:\".format(h), head_token_shift1_shape)\n",
    "#         print(\"[rank_mixer_layer] head_token[{}] shift2 static shape:\".format(h), head_token_shift2_shape)\n",
    "        \n",
    "    \n",
    "#         head_mixed = tf.concat([head_token_shift1, head_token_shift2], axis=-1)\n",
    "        head_mixed = head_token\n",
    "        head_mixed_shape = head_mixed.get_shape().as_list()\n",
    "        head_mixed = tf.Print(head_mixed, [tf.shape(head_mixed)], message=\"[rank_mixer_layer] head_mixed[{}] shape after concat: \".format(h), summarize=10)\n",
    "        print(\"[rank_mixer_layer] head_mixed[{}] static shape:\".format(h), head_mixed_shape)\n",
    "        mixed_tokens.append(head_mixed)\n",
    "    \n",
    "    mixed_tokens = tf.concat(mixed_tokens, axis=-1)  # [B, T-1, H*2*D_h]\n",
    "    mixed_tokens_shape = mixed_tokens.get_shape().as_list()\n",
    "    mixed_tokens = tf.Print(mixed_tokens, [tf.shape(mixed_tokens)], message=\"[rank_mixer_layer] mixed_tokens shape after concat all heads: \", summarize=10)\n",
    "    print(\"[rank_mixer_layer] mixed_tokens static shape:\", mixed_tokens_shape)\n",
    "\n",
    "    # Step3: 逐 Token 前馈网络\n",
    "    ff_out = tf.layers.dense(mixed_tokens, hidden_dim, activation=tf.nn.relu)\n",
    "    ff_out_shape = ff_out.get_shape().as_list()\n",
    "    ff_out = tf.Print(ff_out, [tf.shape(ff_out)], message=\"[rank_mixer_layer] ff_out shape after first dense (hidden_dim={}): \".format(hidden_dim), summarize=10)\n",
    "    print(\"[rank_mixer_layer] ff_out static shape after first dense:\", ff_out_shape)\n",
    "    \n",
    "    ff_out = tf.layers.dense(ff_out, token_dim)\n",
    "    ff_out_shape2 = ff_out.get_shape().as_list()\n",
    "    ff_out = tf.Print(ff_out, [tf.shape(ff_out)], message=\"[rank_mixer_layer] ff_out shape after second dense (token_dim={}): \".format(token_dim), summarize=10)\n",
    "    print(\"[rank_mixer_layer] ff_out static shape after second dense:\", ff_out_shape2)\n",
    "    \n",
    "    output = tf.reduce_mean(ff_out, axis=1)  # Token 维度聚合 [B, D_t]\n",
    "    output_shape = output.get_shape().as_list()\n",
    "    output = tf.Print(output, [tf.shape(output)], message=\"[rank_mixer_layer] output shape after reduce_mean: \", summarize=10)\n",
    "    print(\"[rank_mixer_layer] output static shape:\", output_shape)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# ===================== 3. 定义 MHA 核心层 =====================\n",
    "def mha_layer(inputs, head_num=4, hidden_dim=64):\n",
    "    batch_size = tf.shape(inputs)[0]\n",
    "    input_dim = inputs.get_shape().as_list()[-1]\n",
    "\n",
    "    # 构造 Q/K/V 向量\n",
    "    q = tf.layers.dense(inputs, hidden_dim, activation=tf.nn.relu)\n",
    "    k = tf.layers.dense(inputs, hidden_dim, activation=tf.nn.relu)\n",
    "    v = tf.layers.dense(inputs, hidden_dim, activation=tf.nn.relu)\n",
    "\n",
    "    # 适配 MHA 3D 输入格式 [B, T, D]，构造 T=1 的序列\n",
    "    q = tf.expand_dims(q, axis=1)\n",
    "    k = tf.expand_dims(k, axis=1)\n",
    "    v = tf.expand_dims(v, axis=1)\n",
    "\n",
    "    # 自定义多头注意力计算\n",
    "    def scaled_dot_product_attention(q, k, v):\n",
    "        matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "        dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "        scaled_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "        attention_weights = tf.nn.softmax(scaled_logits, axis=-1)\n",
    "        output = tf.matmul(attention_weights, v)\n",
    "        return output\n",
    "\n",
    "    # 分头计算\n",
    "    q_split = tf.split(q, head_num, axis=-1)\n",
    "    k_split = tf.split(k, head_num, axis=-1)\n",
    "    v_split = tf.split(v, head_num, axis=-1)\n",
    "\n",
    "    outputs = []\n",
    "    for q_h, k_h, v_h in zip(q_split, k_split, v_split):\n",
    "        outputs.append(scaled_dot_product_attention(q_h, k_h, v_h))\n",
    "    concat_output = tf.concat(outputs, axis=-1)\n",
    "    \n",
    "    # 全连接层整合\n",
    "    output = tf.layers.dense(concat_output, hidden_dim)\n",
    "    return tf.squeeze(output, axis=1)\n",
    "\n",
    "# ===================== 4. 构建完整模型 =====================\n",
    "def build_model(inputs, labels, model_type=\"rankmixer\"):\n",
    "    input_layer = tf.reshape(inputs, [-1, inputs.get_shape().as_list()[-1]])\n",
    "    # 共享底层特征映射\n",
    "    hidden = tf.layers.dense(input_layer, 128, activation=tf.nn.relu)\n",
    "    hidden = tf.layers.dropout(hidden, rate=0.2, training=True)\n",
    "\n",
    "    # 核心层选择\n",
    "    if model_type == \"rankmixer\":\n",
    "        core_out = rank_mixer_layer(hidden)\n",
    "    elif model_type == \"mha\":\n",
    "        core_out = mha_layer(hidden)\n",
    "    else:\n",
    "        raise ValueError(\"model_type must be 'rankmixer' or 'mha'\")\n",
    "\n",
    "    # 输出层（二分类）\n",
    "    logits = tf.layers.dense(core_out, 1)\n",
    "    preds = tf.nn.sigmoid(logits)\n",
    "\n",
    "    # 损失函数与优化器\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits=logits, labels=tf.reshape(labels, [-1, 1])\n",
    "        )\n",
    "    )\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "    return preds, loss, optimizer\n",
    "\n",
    "# ===================== 5. 模型训练与评估 =====================\n",
    "def train_and_evaluate(model_type, x_train, x_test, y_train, y_test, feat_dim):\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        # 定义占位符\n",
    "        x_ph = tf.placeholder(tf.float32, [None, feat_dim])\n",
    "        y_ph = tf.placeholder(tf.float32, [None])\n",
    "        preds, loss, optimizer = build_model(x_ph, y_ph, model_type)\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        # 训练参数\n",
    "        epochs = 20\n",
    "        batch_size = 256\n",
    "        train_steps = len(x_train) // batch_size\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "            print(\"=== Training {} Model ===\".format(model_type.upper()))\n",
    "            for epoch in range(epochs):\n",
    "                epoch_loss = 0.0\n",
    "                # 批次训练\n",
    "                for step in range(train_steps):\n",
    "                    start_idx = step * batch_size\n",
    "                    end_idx = start_idx + batch_size\n",
    "                    batch_x = x_train[start_idx:end_idx]\n",
    "                    batch_y = y_train[start_idx:end_idx]\n",
    "                    _, batch_loss_val = sess.run(\n",
    "                        [optimizer, loss],\n",
    "                        feed_dict={x_ph: batch_x, y_ph: batch_y}\n",
    "                    )\n",
    "                    epoch_loss += batch_loss_val\n",
    "                # 计算测试集 AUC\n",
    "                y_pred_val = sess.run(preds, feed_dict={x_ph: x_test, y_ph: y_test})\n",
    "                auc_val = roc_auc_score(y_test, y_pred_val)\n",
    "                print(\"Epoch {}/{}, Avg Loss: {:.4f}, Test AUC: {:.4f}\".format(\n",
    "                    epoch+1, epochs, epoch_loss/train_steps, auc_val\n",
    "                ))\n",
    "        return auc_val\n",
    "\n",
    "# ===================== 6. 主函数执行 =====================\n",
    "if __name__ == \"__main__\":\n",
    "    # 生成数据\n",
    "    x_train, x_test, y_train, y_test, feat_dim = generate_ecommerce_data()\n",
    "\n",
    "    # 训练并评估两个模型\n",
    "    auc_rankmixer = train_and_evaluate(\"rankmixer\", x_train, x_test, y_train, y_test, feat_dim)\n",
    "    auc_mha = train_and_evaluate(\"mha\", x_train, x_test, y_train, y_test, feat_dim)\n",
    "\n",
    "    # 结果对比\n",
    "    print(\"\\n=== Final AUC Comparison ===\")\n",
    "    print(\"RankMixer AUC: {:.4f}\".format(auc_rankmixer))\n",
    "    print(\"MHA AUC: {:.4f}\".format(auc_mha))\n",
    "    print(\"AUC Difference (RankMixer - MHA): {:.4f}\".format(auc_rankmixer - auc_mha))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0b3d1a",
   "metadata": {},
   "source": [
    "### 2.0 增加gate门控"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bc752f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('[rank_mixer_layer] inputs static shape:', [None, 128])\n",
      "('[rank_mixer_layer] batch_size (dynamic):', <tf.Tensor 'rank_mixer/strided_slice:0' shape=() dtype=int32>)\n",
      "('[rank_mixer_layer] input_dim:', 128)\n",
      "('[rank_mixer_layer] token_dim:', 32)\n",
      "('[rank_mixer_layer] tokens static shape:', [None, 4, 32])\n",
      "('[rank_mixer_layer] head_dim:', 16)\n",
      "('[rank_mixer_layer] tokens_split static shape:', [None, 4, 2, 16])\n",
      "('[rank_mixer_layer] tokens_split static shape after transpose:', [None, 2, 4, 16])\n",
      "=== Training RANKMIXER Model ===\n",
      "Epoch 1/20, Avg Loss: 0.6001, Test AUC: 0.8580\n",
      "Epoch 2/20, Avg Loss: 0.4171, Test AUC: 0.9010\n",
      "Epoch 3/20, Avg Loss: 0.3733, Test AUC: 0.9137\n",
      "Epoch 4/20, Avg Loss: 0.3514, Test AUC: 0.9224\n",
      "Epoch 5/20, Avg Loss: 0.3414, Test AUC: 0.9256\n",
      "Epoch 6/20, Avg Loss: 0.3308, Test AUC: 0.9272\n",
      "Epoch 7/20, Avg Loss: 0.3264, Test AUC: 0.9283\n",
      "Epoch 8/20, Avg Loss: 0.3199, Test AUC: 0.9317\n",
      "Epoch 9/20, Avg Loss: 0.3161, Test AUC: 0.9335\n",
      "Epoch 10/20, Avg Loss: 0.3112, Test AUC: 0.9330\n",
      "Epoch 11/20, Avg Loss: 0.3055, Test AUC: 0.9352\n",
      "Epoch 12/20, Avg Loss: 0.3025, Test AUC: 0.9390\n",
      "Epoch 13/20, Avg Loss: 0.2972, Test AUC: 0.9406\n",
      "Epoch 14/20, Avg Loss: 0.2919, Test AUC: 0.9388\n",
      "Epoch 15/20, Avg Loss: 0.2921, Test AUC: 0.9404\n",
      "Epoch 16/20, Avg Loss: 0.2866, Test AUC: 0.9399\n",
      "Epoch 17/20, Avg Loss: 0.2856, Test AUC: 0.9434\n",
      "Epoch 18/20, Avg Loss: 0.2802, Test AUC: 0.9452\n",
      "Epoch 19/20, Avg Loss: 0.2783, Test AUC: 0.9440\n",
      "Epoch 20/20, Avg Loss: 0.2743, Test AUC: 0.9434\n",
      "('[rank_mixer_layer] inputs static shape:', [None, 128])\n",
      "('[rank_mixer_layer] batch_size (dynamic):', <tf.Tensor 'rank_mixer/strided_slice:0' shape=() dtype=int32>)\n",
      "('[rank_mixer_layer] input_dim:', 128)\n",
      "('[rank_mixer_layer] token_dim:', 32)\n",
      "('[rank_mixer_layer] tokens static shape:', [None, 4, 32])\n",
      "('[rank_mixer_layer] head_dim:', 16)\n",
      "('[rank_mixer_layer] tokens_split static shape:', [None, 4, 2, 16])\n",
      "('[rank_mixer_layer] tokens_split static shape after transpose:', [None, 2, 4, 16])\n",
      "=== Training RANKMIXER_GATE Model ===\n",
      "Epoch 1/20, Avg Loss: 0.6118, Test AUC: 0.8335\n",
      "Epoch 2/20, Avg Loss: 0.4486, Test AUC: 0.8885\n",
      "Epoch 3/20, Avg Loss: 0.3973, Test AUC: 0.9014\n",
      "Epoch 4/20, Avg Loss: 0.3734, Test AUC: 0.9114\n",
      "Epoch 5/20, Avg Loss: 0.3548, Test AUC: 0.9195\n",
      "Epoch 6/20, Avg Loss: 0.3448, Test AUC: 0.9220\n",
      "Epoch 7/20, Avg Loss: 0.3354, Test AUC: 0.9234\n",
      "Epoch 8/20, Avg Loss: 0.3279, Test AUC: 0.9266\n",
      "Epoch 9/20, Avg Loss: 0.3180, Test AUC: 0.9296\n",
      "Epoch 10/20, Avg Loss: 0.3137, Test AUC: 0.9321\n",
      "Epoch 11/20, Avg Loss: 0.3118, Test AUC: 0.9333\n",
      "Epoch 12/20, Avg Loss: 0.3016, Test AUC: 0.9361\n",
      "Epoch 13/20, Avg Loss: 0.3002, Test AUC: 0.9380\n",
      "Epoch 14/20, Avg Loss: 0.2920, Test AUC: 0.9383\n",
      "Epoch 15/20, Avg Loss: 0.2927, Test AUC: 0.9396\n",
      "Epoch 16/20, Avg Loss: 0.2886, Test AUC: 0.9404\n",
      "Epoch 17/20, Avg Loss: 0.2832, Test AUC: 0.9418\n",
      "Epoch 18/20, Avg Loss: 0.2804, Test AUC: 0.9417\n",
      "Epoch 19/20, Avg Loss: 0.2772, Test AUC: 0.9418\n",
      "Epoch 20/20, Avg Loss: 0.2766, Test AUC: 0.9447\n",
      "=== Training MHA Model ===\n",
      "Epoch 1/20, Avg Loss: 0.6037, Test AUC: 0.8360\n",
      "Epoch 2/20, Avg Loss: 0.4539, Test AUC: 0.8813\n",
      "Epoch 3/20, Avg Loss: 0.4064, Test AUC: 0.8983\n",
      "Epoch 4/20, Avg Loss: 0.3830, Test AUC: 0.9038\n",
      "Epoch 5/20, Avg Loss: 0.3670, Test AUC: 0.9116\n",
      "Epoch 6/20, Avg Loss: 0.3579, Test AUC: 0.9164\n",
      "Epoch 7/20, Avg Loss: 0.3443, Test AUC: 0.9231\n",
      "Epoch 8/20, Avg Loss: 0.3308, Test AUC: 0.9244\n",
      "Epoch 9/20, Avg Loss: 0.3245, Test AUC: 0.9316\n",
      "Epoch 10/20, Avg Loss: 0.3190, Test AUC: 0.9294\n",
      "Epoch 11/20, Avg Loss: 0.3116, Test AUC: 0.9307\n",
      "Epoch 12/20, Avg Loss: 0.3072, Test AUC: 0.9344\n",
      "Epoch 13/20, Avg Loss: 0.3016, Test AUC: 0.9347\n",
      "Epoch 14/20, Avg Loss: 0.2936, Test AUC: 0.9338\n",
      "Epoch 15/20, Avg Loss: 0.2906, Test AUC: 0.9360\n",
      "Epoch 16/20, Avg Loss: 0.2846, Test AUC: 0.9374\n",
      "Epoch 17/20, Avg Loss: 0.2854, Test AUC: 0.9396\n",
      "Epoch 18/20, Avg Loss: 0.2763, Test AUC: 0.9390\n",
      "Epoch 19/20, Avg Loss: 0.2772, Test AUC: 0.9421\n",
      "Epoch 20/20, Avg Loss: 0.2744, Test AUC: 0.9419\n",
      "\n",
      "=== Final AUC Comparison ===\n",
      "RankMixer AUC: 0.9434\n",
      "RankMixerGate AUC: 0.9447\n",
      "MHA AUC: 0.9419\n",
      "AUC Difference (RankMixer - MHA): 0.0015\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 判断是否使用TF2.x，如果是则切换到兼容模式\n",
    "if tf.__version__.startswith('2'):\n",
    "    import tensorflow.compat.v1 as tf\n",
    "    tf.disable_v2_behavior()\n",
    "\n",
    "# 固定随机种子\n",
    "np.random.seed(2024)\n",
    "tf.set_random_seed(2024)\n",
    "\n",
    "    \n",
    "# ===================== 1. 生成电商样例数据（未修改）====================\n",
    "def generate_ecommerce_data():\n",
    "    # 数据参数\n",
    "    user_num = 10000\n",
    "    item_num = 5000\n",
    "    sample_num = 100000\n",
    "    user_feat_dim = 16  # 用户特征：年龄、性别、购买力等\n",
    "    item_feat_dim = 16  # 商品特征：品类、价格、评分等\n",
    "    behavior_feat_dim = 8  # 行为特征：点击频次、浏览时长等\n",
    "\n",
    "    # 生成连续特征\n",
    "    user_feats = np.random.normal(0, 1, (sample_num, user_feat_dim))\n",
    "    item_feats = np.random.normal(0, 1, (sample_num, item_feat_dim))\n",
    "    behavior_feats = np.random.normal(0, 1, (sample_num, behavior_feat_dim))\n",
    "\n",
    "    # 生成点击标签（基于用户-商品特征内积 + 噪声）\n",
    "    logits = np.sum(user_feats * item_feats, axis=1) + np.random.normal(0, 0.5, sample_num)\n",
    "    labels = (logits > 0).astype(np.float32)\n",
    "\n",
    "    # 合并特征并划分训练/测试集\n",
    "    all_feats = np.concatenate([user_feats, item_feats, behavior_feats], axis=1)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        all_feats, labels, test_size=0.2, random_state=2024\n",
    "    )\n",
    "    return x_train, x_test, y_train, y_test, all_feats.shape[1]\n",
    "\n",
    "# ===================== 2. 定义 RankMixer 核心层（修复变量作用域）====================\n",
    "def rank_mixer_layer(inputs, token_num=4, head_num=2, hidden_dim=64, is_gate=False):\n",
    "    # 添加顶层变量作用域防止重复\n",
    "    with tf.variable_scope('rank_mixer', reuse=tf.AUTO_REUSE):\n",
    "        # 打印输入 shape\n",
    "        inputs_shape = inputs.get_shape().as_list()\n",
    "        inputs = tf.Print(inputs, [tf.shape(inputs)], message=\"[rank_mixer_layer] inputs shape: \", summarize=10)\n",
    "        print(\"[rank_mixer_layer] inputs static shape:\", inputs_shape)\n",
    "        \n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        input_dim = inputs.get_shape().as_list()[-1]\n",
    "        print(\"[rank_mixer_layer] batch_size (dynamic):\", batch_size)\n",
    "        print(\"[rank_mixer_layer] input_dim:\", input_dim)\n",
    "\n",
    "        # Step1: 特征 Token 化（均匀划分）\n",
    "        token_dim = input_dim // token_num\n",
    "        print(\"[rank_mixer_layer] token_dim:\", token_dim)\n",
    "        tokens = tf.reshape(inputs, [batch_size, token_num, token_dim])  # [B, T, D_t]\n",
    "        tokens_shape = tokens.get_shape().as_list()\n",
    "        tokens = tf.Print(tokens, [tf.shape(tokens)], message=\"[rank_mixer_layer] tokens shape after reshape: \", summarize=10)\n",
    "        print(\"[rank_mixer_layer] tokens static shape:\", tokens_shape)\n",
    "\n",
    "        # Step2: 多头 Token 混合（无参跨 Token 交互）\n",
    "        head_dim = token_dim // head_num\n",
    "        print(\"[rank_mixer_layer] head_dim:\", head_dim)\n",
    "        tokens_split = tf.reshape(tokens, [batch_size, token_num, head_num, head_dim])\n",
    "        tokens_split_shape = tokens_split.get_shape().as_list()\n",
    "        tokens_split = tf.Print(tokens_split, [tf.shape(tokens_split)], message=\"[rank_mixer_layer] tokens_split shape after reshape: \", summarize=10)\n",
    "        print(\"[rank_mixer_layer] tokens_split static shape:\", tokens_split_shape)\n",
    "        \n",
    "        tokens_split = tf.transpose(tokens_split, [0, 2, 1, 3])  # [B, H, T, D_h]\n",
    "        tokens_split_shape_transposed = tokens_split.get_shape().as_list()\n",
    "        tokens_split = tf.Print(tokens_split, [tf.shape(tokens_split)], message=\"[rank_mixer_layer] tokens_split shape after transpose: \", summarize=10)\n",
    "        print(\"[rank_mixer_layer] tokens_split static shape after transpose:\", tokens_split_shape_transposed)\n",
    "\n",
    "        mixed_tokens = []\n",
    "        for h in range(head_num):\n",
    "            with tf.variable_scope('head_{}_gate'.format(h), reuse=tf.AUTO_REUSE):\n",
    "                head_token = tokens_split[:, h, :, :]\n",
    "                head_token_shape = head_token.get_shape().as_list()\n",
    "                head_token = tf.Print(head_token, [tf.shape(head_token)], \n",
    "                                     message=\"[rank_mixer_layer] head_token[{}] shape: \".format(h), summarize=10)\n",
    "                head_mixed = head_token\n",
    "                if is_gate:\n",
    "                    # 新增门控机制（类似LSTM的Gate）\n",
    "                    gate = tf.layers.dense(  # 生成Gate权重\n",
    "                        inputs=head_token,\n",
    "                        units=head_token.shape[-1],  # 保持维度一致\n",
    "                        activation=tf.nn.sigmoid,\n",
    "                        name='gate_dense'  # 固定名称但放在独立作用域下\n",
    "                    )\n",
    "\n",
    "                    # 应用门控\n",
    "                    gated_head_token = head_token * gate\n",
    "                    gated_head_token = tf.Print(gated_head_token, \n",
    "                                               [tf.shape(gated_head_token)], \n",
    "                                               message=\"[rank_mixer_layer] gated_head_token[{}] shape: \".format(h), summarize=10)\n",
    "\n",
    "                    # 增加跨Token交互（保持原有逻辑）\n",
    "                    head_mixed = tf.concat([  # 使用拼接混合\n",
    "                        gated_head_token[:, 1:, :],  # 向前位移1\n",
    "                        gated_head_token[:, :-1, :],  # 向后位移1\n",
    "                    ], axis=-1)\n",
    "                \n",
    "                head_mixed_shape = head_mixed.get_shape().as_list()\n",
    "                head_mixed = tf.Print(head_mixed, [tf.shape(head_mixed)], \n",
    "                                     message=\"[rank_mixer_layer] head_mixed[{}] shape after concat: \".format(h), summarize=10)\n",
    "                mixed_tokens.append(head_mixed)\n",
    "        \n",
    "        mixed_tokens = tf.concat(mixed_tokens, axis=-1)  # [B, T-1, H*2*D_h]\n",
    "        mixed_tokens_shape = mixed_tokens.get_shape().as_list()\n",
    "        mixed_tokens = tf.Print(mixed_tokens, [tf.shape(mixed_tokens)], \n",
    "                              message=\"[rank_mixer_layer] mixed_tokens shape after concat all heads: \", summarize=10)\n",
    "        \n",
    "        # Step3: 逐 Token 前馈网络（保持原有逻辑）\n",
    "        ff_out = tf.layers.dense(mixed_tokens, hidden_dim, activation=tf.nn.relu)\n",
    "        ff_out = tf.Print(ff_out, [tf.shape(ff_out)], \n",
    "                         message=\"[rank_mixer_layer] ff_out shape after first dense (hidden_dim={}): \".format(hidden_dim), summarize=10)\n",
    "        \n",
    "        ff_out = tf.layers.dense(ff_out, token_dim)\n",
    "        ff_out = tf.Print(ff_out, [tf.shape(ff_out)], \n",
    "                         message=\"[rank_mixer_layer] ff_out shape after second dense (token_dim={}): \".format(token_dim), summarize=10)\n",
    "        \n",
    "        output = tf.reduce_mean(ff_out, axis=1)  # Token 维度聚合 [B, D_t]\n",
    "        output_shape = output.get_shape().as_list()\n",
    "        output = tf.Print(output, [tf.shape(output)], \n",
    "                         message=\"[rank_mixer_layer] output shape after reduce_mean: \", summarize=10)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# ===================== 3. 其他层和模型构建（未修改）====================\n",
    "def mha_layer(inputs, head_num=4, hidden_dim=64):\n",
    "    batch_size = tf.shape(inputs)[0]\n",
    "    input_dim = inputs.get_shape().as_list()[-1]\n",
    "\n",
    "    # 构造 Q/K/V 向量\n",
    "    q = tf.layers.dense(inputs, hidden_dim, activation=tf.nn.relu)\n",
    "    k = tf.layers.dense(inputs, hidden_dim, activation=tf.nn.relu)\n",
    "    v = tf.layers.dense(inputs, hidden_dim, activation=tf.nn.relu)\n",
    "\n",
    "    # 适配 MHA 3D 输入格式 [B, T, D]，构造 T=1 的序列\n",
    "    q = tf.expand_dims(q, axis=1)\n",
    "    k = tf.expand_dims(k, axis=1)\n",
    "    v = tf.expand_dims(v, axis=1)\n",
    "\n",
    "    # 自定义多头注意力计算\n",
    "    def scaled_dot_product_attention(q, k, v):\n",
    "        matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "        dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "        scaled_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "        attention_weights = tf.nn.softmax(scaled_logits, axis=-1)\n",
    "        output = tf.matmul(attention_weights, v)\n",
    "        return output\n",
    "\n",
    "    # 分头计算\n",
    "    q_split = tf.split(q, head_num, axis=-1)\n",
    "    k_split = tf.split(k, head_num, axis=-1)\n",
    "    v_split = tf.split(v, head_num, axis=-1)\n",
    "\n",
    "    outputs = []\n",
    "    for q_h, k_h, v_h in zip(q_split, k_split, v_split):\n",
    "        outputs.append(scaled_dot_product_attention(q_h, k_h, v_h))\n",
    "    concat_output = tf.concat(outputs, axis=-1)\n",
    "    \n",
    "    # 全连接层整合\n",
    "    output = tf.layers.dense(concat_output, hidden_dim)\n",
    "    return tf.squeeze(output, axis=1)\n",
    "\n",
    "def build_model(inputs, labels, model_type=\"rankmixer\"):\n",
    "    input_layer = tf.reshape(inputs, [-1, inputs.get_shape().as_list()[-1]])\n",
    "    # 共享底层特征映射\n",
    "    hidden = tf.layers.dense(input_layer, 128, activation=tf.nn.relu)\n",
    "    hidden = tf.layers.dropout(hidden, rate=0.2, training=True)\n",
    "\n",
    "    # 核心层选择\n",
    "    if model_type == \"rankmixer\":\n",
    "        core_out = rank_mixer_layer(hidden,token_num=4, head_num=2, hidden_dim=64, is_gate=False)\n",
    "    elif model_type == \"mha\":\n",
    "        core_out = mha_layer(hidden)\n",
    "    elif model_type == \"rankmixer_gate\":\n",
    "        core_out = rank_mixer_layer(hidden,token_num=4, head_num=2, hidden_dim=64, is_gate=True)\n",
    "    else:\n",
    "        raise ValueError(\"model_type must be 'rankmixer' or 'mha'\")\n",
    "\n",
    "    # 输出层（二分类）\n",
    "    logits = tf.layers.dense(core_out, 1)\n",
    "    preds = tf.nn.sigmoid(logits)\n",
    "\n",
    "    # 损失函数与优化器\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits=logits, labels=tf.reshape(labels, [-1, 1])\n",
    "        )\n",
    "    )\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "    return preds, loss, optimizer\n",
    "\n",
    "def train_and_evaluate(model_type, x_train, x_test, y_train, y_test, feat_dim):\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        # 定义占位符\n",
    "        x_ph = tf.placeholder(tf.float32, [None, feat_dim])\n",
    "        y_ph = tf.placeholder(tf.float32, [None])\n",
    "        preds, loss, optimizer = build_model(x_ph, y_ph, model_type)\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        # 训练参数\n",
    "        epochs = 20\n",
    "        batch_size = 256\n",
    "        train_steps = len(x_train) // batch_size\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "            print(\"=== Training {} Model ===\".format(model_type.upper()))\n",
    "            for epoch in range(epochs):\n",
    "                epoch_loss = 0.0\n",
    "                # 批次训练\n",
    "                for step in range(train_steps):\n",
    "                    start_idx = step * batch_size\n",
    "                    end_idx = start_idx + batch_size\n",
    "                    batch_x = x_train[start_idx:end_idx]\n",
    "                    batch_y = y_train[start_idx:end_idx]\n",
    "                    _, batch_loss_val = sess.run(\n",
    "                        [optimizer, loss],\n",
    "                        feed_dict={x_ph: batch_x, y_ph: batch_y}\n",
    "                    )\n",
    "                    epoch_loss += batch_loss_val\n",
    "                # 计算测试集 AUC\n",
    "                y_pred_val = sess.run(preds, feed_dict={x_ph: x_test, y_ph: y_test})\n",
    "                auc_val = roc_auc_score(y_test, y_pred_val)\n",
    "                print(\"Epoch {}/{}, Avg Loss: {:.4f}, Test AUC: {:.4f}\".format(\n",
    "                    epoch+1, epochs, epoch_loss/train_steps, auc_val\n",
    "                ))\n",
    "        return auc_val\n",
    "\n",
    "# ===================== 4. 主函数执行（未修改）====================\n",
    "if __name__ == \"__main__\":\n",
    "    # 生成数据\n",
    "    x_train, x_test, y_train, y_test, feat_dim = generate_ecommerce_data()\n",
    "\n",
    "    # 训练并评估两个模型\n",
    "    auc_rankmixer = train_and_evaluate(\"rankmixer\", x_train, x_test, y_train, y_test, feat_dim)\n",
    "    auc_rankmixer_gate = train_and_evaluate(\"rankmixer_gate\", x_train, x_test, y_train, y_test, feat_dim)\n",
    "    auc_mha = train_and_evaluate(\"mha\", x_train, x_test, y_train, y_test, feat_dim)\n",
    "\n",
    "    # 结果对比\n",
    "    print(\"\\n=== Final AUC Comparison ===\")\n",
    "    print(\"RankMixer AUC: {:.4f}\".format(auc_rankmixer))\n",
    "    print(\"RankMixerGate AUC: {:.4f}\".format(auc_rankmixer_gate))\n",
    "    print(\"MHA AUC: {:.4f}\".format(auc_mha))\n",
    "    print(\"AUC Difference (RankMixer - MHA): {:.4f}\".format(auc_rankmixer - auc_mha))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7931585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6113e993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b74841e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8382d684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden shape:[None, 128]\n",
      "core_out shape:[None, 32]\n",
      "=== Training RANKMIXER Model ===\n",
      "Epoch 1/20, Avg Loss: 0.5957, Test AUC: 0.8637\n",
      "Epoch 2/20, Avg Loss: 0.4177, Test AUC: 0.9065\n",
      "Epoch 3/20, Avg Loss: 0.3723, Test AUC: 0.9174\n",
      "Epoch 4/20, Avg Loss: 0.3508, Test AUC: 0.9234\n",
      "Epoch 5/20, Avg Loss: 0.3429, Test AUC: 0.9254\n",
      "Epoch 6/20, Avg Loss: 0.3328, Test AUC: 0.9284\n",
      "Epoch 7/20, Avg Loss: 0.3233, Test AUC: 0.9283\n",
      "Epoch 8/20, Avg Loss: 0.3160, Test AUC: 0.9341\n",
      "Epoch 9/20, Avg Loss: 0.3096, Test AUC: 0.9328\n",
      "Epoch 10/20, Avg Loss: 0.3065, Test AUC: 0.9371\n",
      "Epoch 11/20, Avg Loss: 0.3047, Test AUC: 0.9383\n",
      "Epoch 12/20, Avg Loss: 0.2978, Test AUC: 0.9380\n",
      "Epoch 13/20, Avg Loss: 0.2954, Test AUC: 0.9412\n",
      "Epoch 14/20, Avg Loss: 0.2900, Test AUC: 0.9415\n",
      "Epoch 15/20, Avg Loss: 0.2898, Test AUC: 0.9401\n",
      "Epoch 16/20, Avg Loss: 0.2835, Test AUC: 0.9444\n",
      "Epoch 17/20, Avg Loss: 0.2788, Test AUC: 0.9440\n",
      "Epoch 18/20, Avg Loss: 0.2761, Test AUC: 0.9452\n",
      "Epoch 19/20, Avg Loss: 0.2783, Test AUC: 0.9443\n",
      "Epoch 20/20, Avg Loss: 0.2724, Test AUC: 0.9461\n",
      "hidden shape:[None, 128]\n",
      "core_out shape:[None, 32]\n",
      "=== Training RANKMIXER_4_2_64 Model ===\n",
      "Epoch 1/20, Avg Loss: 0.5956, Test AUC: 0.8263\n",
      "Epoch 2/20, Avg Loss: 0.4594, Test AUC: 0.8800\n",
      "Epoch 3/20, Avg Loss: 0.4144, Test AUC: 0.8922\n",
      "Epoch 4/20, Avg Loss: 0.3910, Test AUC: 0.8983\n",
      "Epoch 5/20, Avg Loss: 0.3746, Test AUC: 0.9075\n",
      "Epoch 6/20, Avg Loss: 0.3615, Test AUC: 0.9122\n",
      "Epoch 7/20, Avg Loss: 0.3524, Test AUC: 0.9163\n",
      "Epoch 8/20, Avg Loss: 0.3430, Test AUC: 0.9174\n",
      "Epoch 9/20, Avg Loss: 0.3357, Test AUC: 0.9206\n",
      "Epoch 10/20, Avg Loss: 0.3293, Test AUC: 0.9232\n",
      "Epoch 11/20, Avg Loss: 0.3227, Test AUC: 0.9274\n",
      "Epoch 12/20, Avg Loss: 0.3197, Test AUC: 0.9266\n",
      "Epoch 13/20, Avg Loss: 0.3111, Test AUC: 0.9282\n",
      "Epoch 14/20, Avg Loss: 0.3072, Test AUC: 0.9323\n",
      "Epoch 15/20, Avg Loss: 0.3003, Test AUC: 0.9324\n",
      "Epoch 16/20, Avg Loss: 0.2973, Test AUC: 0.9318\n",
      "Epoch 17/20, Avg Loss: 0.2918, Test AUC: 0.9324\n",
      "Epoch 18/20, Avg Loss: 0.2919, Test AUC: 0.9363\n",
      "Epoch 19/20, Avg Loss: 0.2867, Test AUC: 0.9373\n",
      "Epoch 20/20, Avg Loss: 0.2809, Test AUC: 0.9397\n",
      "hidden shape:[None, 128]\n",
      "core_out shape:[None, 64]\n",
      "=== Training RANKMIXER_2_4_64 Model ===\n",
      "Epoch 1/20, Avg Loss: 0.5972, Test AUC: 0.8419\n",
      "Epoch 2/20, Avg Loss: 0.4432, Test AUC: 0.8893\n",
      "Epoch 3/20, Avg Loss: 0.3924, Test AUC: 0.9004\n",
      "Epoch 4/20, Avg Loss: 0.3687, Test AUC: 0.9148\n",
      "Epoch 5/20, Avg Loss: 0.3534, Test AUC: 0.9198\n",
      "Epoch 6/20, Avg Loss: 0.3432, Test AUC: 0.9219\n",
      "Epoch 7/20, Avg Loss: 0.3317, Test AUC: 0.9290\n",
      "Epoch 8/20, Avg Loss: 0.3241, Test AUC: 0.9301\n",
      "Epoch 9/20, Avg Loss: 0.3158, Test AUC: 0.9321\n",
      "Epoch 10/20, Avg Loss: 0.3080, Test AUC: 0.9348\n",
      "Epoch 11/20, Avg Loss: 0.3014, Test AUC: 0.9355\n",
      "Epoch 12/20, Avg Loss: 0.2978, Test AUC: 0.9399\n",
      "Epoch 13/20, Avg Loss: 0.2902, Test AUC: 0.9410\n",
      "Epoch 14/20, Avg Loss: 0.2845, Test AUC: 0.9414\n",
      "Epoch 15/20, Avg Loss: 0.2825, Test AUC: 0.9429\n",
      "Epoch 16/20, Avg Loss: 0.2774, Test AUC: 0.9457\n",
      "Epoch 17/20, Avg Loss: 0.2808, Test AUC: 0.9454\n",
      "Epoch 18/20, Avg Loss: 0.2715, Test AUC: 0.9472\n",
      "Epoch 19/20, Avg Loss: 0.2679, Test AUC: 0.9464\n",
      "Epoch 20/20, Avg Loss: 0.2686, Test AUC: 0.9472\n",
      "hidden shape:[None, 128]\n",
      "core_out shape:[None, 128]\n",
      "=== Training RANKMIXER_1_8_64 Model ===\n",
      "Epoch 1/20, Avg Loss: 0.5939, Test AUC: 0.8352\n",
      "Epoch 2/20, Avg Loss: 0.4497, Test AUC: 0.8774\n",
      "Epoch 3/20, Avg Loss: 0.4093, Test AUC: 0.8929\n",
      "Epoch 4/20, Avg Loss: 0.3906, Test AUC: 0.9023\n",
      "Epoch 5/20, Avg Loss: 0.3743, Test AUC: 0.9072\n",
      "Epoch 6/20, Avg Loss: 0.3615, Test AUC: 0.9101\n",
      "Epoch 7/20, Avg Loss: 0.3494, Test AUC: 0.9136\n",
      "Epoch 8/20, Avg Loss: 0.3425, Test AUC: 0.9167\n",
      "Epoch 9/20, Avg Loss: 0.3359, Test AUC: 0.9204\n",
      "Epoch 10/20, Avg Loss: 0.3274, Test AUC: 0.9234\n",
      "Epoch 11/20, Avg Loss: 0.3229, Test AUC: 0.9274\n",
      "Epoch 12/20, Avg Loss: 0.3157, Test AUC: 0.9263\n",
      "Epoch 13/20, Avg Loss: 0.3117, Test AUC: 0.9307\n",
      "Epoch 14/20, Avg Loss: 0.3055, Test AUC: 0.9280\n",
      "Epoch 15/20, Avg Loss: 0.3032, Test AUC: 0.9312\n",
      "Epoch 16/20, Avg Loss: 0.3021, Test AUC: 0.9304\n",
      "Epoch 17/20, Avg Loss: 0.2943, Test AUC: 0.9317\n",
      "Epoch 18/20, Avg Loss: 0.2894, Test AUC: 0.9370\n",
      "Epoch 19/20, Avg Loss: 0.2882, Test AUC: 0.9373\n",
      "Epoch 20/20, Avg Loss: 0.2822, Test AUC: 0.9372\n",
      "hidden shape:[None, 128]\n",
      "core_out shape:[None, 64]\n",
      "=== Training MHA Model ===\n",
      "Epoch 1/20, Avg Loss: 0.6063, Test AUC: 0.8301\n",
      "Epoch 2/20, Avg Loss: 0.4636, Test AUC: 0.8783\n",
      "Epoch 3/20, Avg Loss: 0.4153, Test AUC: 0.8937\n",
      "Epoch 4/20, Avg Loss: 0.3899, Test AUC: 0.9018\n",
      "Epoch 5/20, Avg Loss: 0.3752, Test AUC: 0.9052\n",
      "Epoch 6/20, Avg Loss: 0.3611, Test AUC: 0.9153\n",
      "Epoch 7/20, Avg Loss: 0.3536, Test AUC: 0.9147\n",
      "Epoch 8/20, Avg Loss: 0.3463, Test AUC: 0.9181\n",
      "Epoch 9/20, Avg Loss: 0.3368, Test AUC: 0.9210\n",
      "Epoch 10/20, Avg Loss: 0.3295, Test AUC: 0.9249\n",
      "Epoch 11/20, Avg Loss: 0.3229, Test AUC: 0.9247\n",
      "Epoch 12/20, Avg Loss: 0.3207, Test AUC: 0.9281\n",
      "Epoch 13/20, Avg Loss: 0.3129, Test AUC: 0.9272\n",
      "Epoch 14/20, Avg Loss: 0.3073, Test AUC: 0.9293\n",
      "Epoch 15/20, Avg Loss: 0.3020, Test AUC: 0.9326\n",
      "Epoch 16/20, Avg Loss: 0.3007, Test AUC: 0.9350\n",
      "Epoch 17/20, Avg Loss: 0.2923, Test AUC: 0.9360\n",
      "Epoch 18/20, Avg Loss: 0.2893, Test AUC: 0.9342\n",
      "Epoch 19/20, Avg Loss: 0.2860, Test AUC: 0.9375\n",
      "Epoch 20/20, Avg Loss: 0.2830, Test AUC: 0.9390\n",
      "\n",
      "=== Final AUC Comparison ===\n",
      "RankMixer AUC: 0.9465\n",
      "RankMixer auc_rankmixer_4_2_64 AUC: 0.9368\n",
      "RankMixer auc_rankmixer_2_4_64 AUC: 0.9496\n",
      "RankMixer auc_rankmixer_1_8_64 AUC: 0.9360\n",
      "MHA AUC: 0.9391\n",
      "AUC Difference (RankMixer - MHA): 0.0075\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 判断是否使用TF2.x，如果是则切换到兼容模式\n",
    "if tf.__version__.startswith('2'):\n",
    "    import tensorflow.compat.v1 as tf\n",
    "    tf.disable_v2_behavior()\n",
    "\n",
    "# 固定随机种子\n",
    "np.random.seed(2024)\n",
    "tf.set_random_seed(2024)\n",
    "\n",
    "def gelu(x):\n",
    "    return x * 0.5 * (1.0 + tf.erf(x / tf.sqrt(2.0)))\n",
    "\n",
    "def generate_ecommerce_data():\n",
    "    # 数据参数\n",
    "    user_num = 10000\n",
    "    item_num = 5000\n",
    "    sample_num = 100000\n",
    "    user_feat_dim = 16  # 用户特征：年龄、性别、购买力等\n",
    "    item_feat_dim = 16  # 商品特征：品类、价格、评分等\n",
    "    behavior_feat_dim = 8  # 行为特征：点击频次、浏览时长等\n",
    "\n",
    "    # 生成连续特征\n",
    "    user_feats = np.random.normal(0, 1, (sample_num, user_feat_dim))\n",
    "    item_feats = np.random.normal(0, 1, (sample_num, item_feat_dim))\n",
    "    behavior_feats = np.random.normal(0, 1, (sample_num, behavior_feat_dim))\n",
    "\n",
    "    # 生成点击标签（基于用户-商品特征内积 + 噪声）\n",
    "    logits = np.sum(user_feats * item_feats, axis=1) + np.random.normal(0, 0.5, sample_num)\n",
    "    labels = (logits > 0).astype(np.float32)\n",
    "\n",
    "    # 合并特征并划分训练/测试集\n",
    "    all_feats = np.concatenate([user_feats, item_feats, behavior_feats], axis=1)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        all_feats, labels, test_size=0.2, random_state=2024\n",
    "    )\n",
    "    return x_train, x_test, y_train, y_test, all_feats.shape[1]\n",
    "\n",
    "def rank_mixer_layer(inputs, token_num=4, head_num=2, hidden_dim=64, is_gate=\"rankmixer\"):\n",
    "    with tf.variable_scope('rank_mixer', reuse=tf.AUTO_REUSE):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        input_dim = inputs.shape[-1].value  # 获取静态维度\n",
    "        token_dim = input_dim // token_num\n",
    "        tokens = tf.reshape(inputs, [batch_size, token_num, token_dim])\n",
    "\n",
    "        head_dim = token_dim // head_num\n",
    "        tokens_split = tf.reshape(tokens, [batch_size, token_num, head_num, head_dim])\n",
    "        tokens_split = tf.transpose(tokens_split, [0, 2, 1, 3])\n",
    "\n",
    "        mixed_tokens = []\n",
    "        for h in range(head_num):\n",
    "            with tf.variable_scope('head_{}_mixer'.format(h), reuse=tf.AUTO_REUSE):\n",
    "                head_token = tokens_split[:, h, :, :]\n",
    "                \n",
    "                if is_gate == \"rankmixer_gate\":\n",
    "\n",
    "                    # 局部混合：使用静态计算的head_dim\n",
    "                    local_mix = tf.layers.dense(\n",
    "                        head_token, head_dim,\n",
    "                        activation=gelu,\n",
    "                        kernel_initializer=tf.keras.initializers.glorot_uniform()\n",
    "                    )\n",
    "\n",
    "                    # 全局混合\n",
    "                    global_avg = tf.reduce_mean(head_token, axis=1, keep_dims=True)\n",
    "                    global_mix = tf.tile(global_avg, [1, head_token.shape[1], 1])\n",
    "\n",
    "                    # 特征拼接\n",
    "                    combined = tf.concat([head_token, local_mix, global_mix], axis=-1)\n",
    "\n",
    "                    # 门控机制：使用静态计算的combined维度\n",
    "                    combined_dim = combined.shape[-1].value\n",
    "                    gate = tf.layers.dense(\n",
    "                        combined, combined_dim,\n",
    "                        activation=tf.nn.sigmoid,\n",
    "                        kernel_initializer=tf.keras.initializers.he_normal()\n",
    "                    )\n",
    "                    gated = combined * gate\n",
    "                    mixed = tf.layers.dense(gated, head_dim)\n",
    "                elif is_gate == \"rankmixer_mlp\":\n",
    "                    mixed = tf.layers.dense(head_token, head_dim)\n",
    "                else:\n",
    "                    mixed = head_token\n",
    "\n",
    "                # 维度变换：使用head_dim\n",
    "                \n",
    "                mixed_tokens.append(mixed)\n",
    "\n",
    "        # 合并所有头的输出\n",
    "        mixed_all = tf.concat(mixed_tokens, axis=-1)\n",
    "        mixed_all = tf.reshape(mixed_all, [batch_size, token_num, token_dim])  # 显式设置形状\n",
    "\n",
    "        # 最终变换\n",
    "        ff_out = tf.layers.dense(mixed_all, hidden_dim, activation=gelu)\n",
    "        ff_out = tf.layers.dense(ff_out, token_dim)\n",
    "\n",
    "        # 输出聚合\n",
    "        output = tf.reduce_mean(ff_out, axis=1)\n",
    "        return output\n",
    "\n",
    "def mha_layer(inputs, head_num=4, hidden_dim=64):\n",
    "    batch_size = tf.shape(inputs)[0]\n",
    "    input_dim = inputs.shape[-1]\n",
    "\n",
    "    q = tf.layers.dense(inputs, hidden_dim, activation=tf.nn.relu)\n",
    "    k = tf.layers.dense(inputs, hidden_dim, activation=tf.nn.relu)\n",
    "    v = tf.layers.dense(inputs, hidden_dim, activation=tf.nn.relu)\n",
    "\n",
    "    q = tf.expand_dims(q, axis=1)\n",
    "    k = tf.expand_dims(k, axis=1)\n",
    "    v = tf.expand_dims(v, axis=1)\n",
    "\n",
    "    def scaled_dot_product_attention(q, k, v):\n",
    "        matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "        dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "        scaled_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "        attention_weights = tf.nn.softmax(scaled_logits, axis=-1)\n",
    "        return tf.matmul(attention_weights, v)\n",
    "\n",
    "    q_split = tf.split(q, head_num, axis=-1)\n",
    "    k_split = tf.split(k, head_num, axis=-1)\n",
    "    v_split = tf.split(v, head_num, axis=-1)\n",
    "\n",
    "    outputs = []\n",
    "    for q_h, k_h, v_h in zip(q_split, k_split, v_split):\n",
    "        outputs.append(scaled_dot_product_attention(q_h, k_h, v_h))\n",
    "    concat_output = tf.concat(outputs, axis=-1)\n",
    "    \n",
    "    output = tf.layers.dense(concat_output, hidden_dim)\n",
    "    return tf.squeeze(output, axis=1)\n",
    "\n",
    "def build_model(inputs, labels, model_type=\"rankmixer\"):\n",
    "    input_layer = tf.reshape(inputs, [-1, inputs.shape[-1]])\n",
    "    hidden = tf.layers.dense(input_layer, 128, activation=tf.nn.relu)\n",
    "    hidden = tf.layers.dropout(hidden, rate=0.2, training=True)\n",
    "    \n",
    "    print(\"hidden shape:{}\".format(hidden.shape.as_list()))\n",
    "\n",
    "    if model_type == \"rankmixer\":\n",
    "        core_out = rank_mixer_layer(hidden,token_num=4, head_num=2, hidden_dim=64, is_gate=\"rankmixer\")\n",
    "    elif model_type == \"rankmixer_mlp\":\n",
    "        core_out = rank_mixer_layer(hidden,token_num=4, head_num=2, hidden_dim=64, is_gate=\"rankmixer_mlp\")\n",
    "    elif model_type == \"rankmixer_gate\":\n",
    "        core_out = rank_mixer_layer(hidden,token_num=4, head_num=2, hidden_dim=64, is_gate=\"rankmixer_gate\")\n",
    "        \n",
    "    elif model_type == \"rankmixer_4_2_64\":\n",
    "        core_out_tmp = mha_layer(hidden)\n",
    "        input_dim = hidden.shape[-1]\n",
    "        hidden = tf.layers.dense(core_out_tmp, input_dim)\n",
    "        core_out = rank_mixer_layer(hidden,token_num=4, head_num=2, hidden_dim=64, is_gate=\"rankmixer\")\n",
    "\n",
    "    elif model_type == \"rankmixer_2_4_64\":\n",
    "        core_out = rank_mixer_layer(hidden,token_num=2, head_num=4, hidden_dim=64, is_gate=\"rankmixer\")\n",
    "    elif model_type == \"rankmixer_1_8_64\":\n",
    "        core_out = rank_mixer_layer(hidden,token_num=1, head_num=8, hidden_dim=64, is_gate=\"rankmixer\")\n",
    "    elif model_type == \"mha\":\n",
    "        core_out = mha_layer(hidden)\n",
    "    else:\n",
    "        raise ValueError(\"model_type must be 'rankmixer' or 'mha'\")\n",
    "\n",
    "        \n",
    "    print(\"core_out shape:{}\".format(core_out.shape.as_list()))\n",
    "    logits = tf.layers.dense(core_out, 1)\n",
    "    preds = tf.nn.sigmoid(logits)\n",
    "\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits=logits, labels=tf.reshape(labels, [-1, 1])\n",
    "        )\n",
    "    )\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "    return preds, loss, optimizer\n",
    "\n",
    "def train_and_evaluate(model_type, x_train, x_test, y_train, y_test, feat_dim):\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        x_ph = tf.placeholder(tf.float32, [None, feat_dim])\n",
    "        y_ph = tf.placeholder(tf.float32, [None])\n",
    "        preds, loss, optimizer = build_model(x_ph, y_ph, model_type)\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        epochs = 20\n",
    "        batch_size = 256\n",
    "        train_steps = len(x_train) // batch_size\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "            print(\"=== Training {} Model ===\".format(model_type.upper()))\n",
    "            for epoch in range(epochs):\n",
    "                epoch_loss = 0.0\n",
    "                for step in range(train_steps):\n",
    "                    batch_x = x_train[step*batch_size:(step+1)*batch_size]\n",
    "                    batch_y = y_train[step*batch_size:(step+1)*batch_size]\n",
    "                    _, loss_val = sess.run([optimizer, loss], \n",
    "                                          {x_ph: batch_x, y_ph: batch_y})\n",
    "                    epoch_loss += loss_val\n",
    "\n",
    "                y_pred = sess.run(preds, {x_ph: x_test})\n",
    "                auc = roc_auc_score(y_test, y_pred)\n",
    "                print(\"Epoch {}/{}, Avg Loss: {:.4f}, Test AUC: {:.4f}\".format(\n",
    "                    epoch+1, epochs, epoch_loss/train_steps, auc\n",
    "                ))\n",
    "\n",
    "            return roc_auc_score(y_test, sess.run(preds, {x_ph: x_test}))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    x_train, x_test, y_train, y_test, feat_dim = generate_ecommerce_data()\n",
    "    auc_rankmixer = train_and_evaluate(\"rankmixer\", x_train, x_test, y_train, y_test, feat_dim)\n",
    "#     auc_rankmixer_mlp = train_and_evaluate(\"rankmixer_mlp\", x_train, x_test, y_train, y_test, feat_dim)\n",
    "#     auc_rankmixer_gate = train_and_evaluate(\"rankmixer_gate\", x_train, x_test, y_train, y_test, feat_dim)\n",
    "    auc_rankmixer_4_2_64 = train_and_evaluate(\"rankmixer_4_2_64\", x_train, x_test, y_train, y_test, feat_dim)\n",
    "    auc_rankmixer_2_4_64 = train_and_evaluate(\"rankmixer_2_4_64\", x_train, x_test, y_train, y_test, feat_dim)\n",
    "    auc_rankmixer_1_8_64 = train_and_evaluate(\"rankmixer_1_8_64\", x_train, x_test, y_train, y_test, feat_dim)\n",
    "\n",
    "    auc_mha = train_and_evaluate(\"mha\", x_train, x_test, y_train, y_test, feat_dim)\n",
    "    \n",
    "    print(\"\\n=== Final AUC Comparison ===\")\n",
    "    print(\"RankMixer AUC: {:.4f}\".format(auc_rankmixer))\n",
    "#     print(\"RankMixerMLP AUC: {:.4f}\".format(auc_rankmixer_gate))\n",
    "#     print(\"RankMixerGATE AUC: {:.4f}\".format(auc_rankmixer_gate))\n",
    "\n",
    "    print(\"RankMixer auc_rankmixer_4_2_64 AUC: {:.4f}\".format(auc_rankmixer_4_2_64))\n",
    "    print(\"RankMixer auc_rankmixer_2_4_64 AUC: {:.4f}\".format(auc_rankmixer_2_4_64))\n",
    "    print(\"RankMixer auc_rankmixer_1_8_64 AUC: {:.4f}\".format(auc_rankmixer_1_8_64))\n",
    "\n",
    "    print(\"MHA AUC: {:.4f}\".format(auc_mha))\n",
    "    print(\"AUC Difference (RankMixer - MHA): {:.4f}\".format(auc_rankmixer - auc_mha))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d88cd23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
